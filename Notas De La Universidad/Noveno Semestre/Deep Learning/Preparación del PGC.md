---
date: 2025-10-27
---
### 1. Introducci칩n (El "Qu칠")

**(Iniciar con el objetivo principal)**

**Ustedes:** "Buenos d칤as. Nuestro proyecto es un sistema inteligente para la **detecci칩n y mitigaci칩n de emociones musicales**. El objetivo es crear una herramienta que no solo identifique la emoci칩n de una canci칩n, sino que act칰e activamente para ayudar a regular el estado de 치nimo del usuario."

"El resultado es un prototipo web funcional que consta de tres componentes clave:

1. **La Demo de Usuario:** Una interfaz para analizar canciones y recibir playlists.
2. **Un Dashboard de M칠tricas:** (Aqu칤 abren `metrics.html`) Una vista para el ingeniero, que valida la calidad y precisi칩n de nuestro modelo de Deep Learning.
3. **Una L칤nea de Tiempo de Trazabilidad:** (Aqu칤 abren `traceability.html`) Una vista para el investigador, que documenta el por qu칠 de nuestras decisiones, los problemas encontrados y los pivotes estrat칠gicos que tomamos."
    

### 2. El Problema (El "Por Qu칠")

**(Justifiquen la relevancia del proyecto)**

**Ustedes:** "El problema que abordamos es que, si bien la m칰sica tiene una influencia profunda en el estado de 치nimo, las herramientas actuales como Spotify son pasivas. Sus algoritmos se centran en _qu칠_ te gusta, no en _c칩mo_ te sientes."

"Se desaprovecha la oportunidad de usar la m칰sica como una herramienta activa de bienestar. Nuestro proyecto busca llenar ese vac칤o, creando un sistema que escuche la emoci칩n actual y proponga un camino musical para regularla."

### 3. La Trazabilidad: Nuestra Investigaci칩n (El "Viaje") 游


**Ustedes:** "Nuestro proceso no fue una l칤nea recta. Tuvimos que adaptarnos a los hallazgos de nuestra investigaci칩n.

- **Fase 1: El Fracaso Inicial (CNN + Audio Crudo)**
    
    - "Al principio, intentamos construir todo desde cero. Usamos un modelo Convolucional (CNN) para analizar el audio crudo de archivos MP3, convirti칠ndolos en im치genes de espectrogramas."
    - "**Resultado:** Fracaso total. El modelo ten칤a un sobreajuste severo (96% en entrenamiento vs 33% en validaci칩n) y un desbalance de clases que lo hac칤a in칰til."
        
- **Fase 2: El Pivote Estrat칠gico (DNN + Features de Spotify)**
    
    - "Decidimos pivotar. En lugar de procesar audio crudo, usamos un dataset masivo de Kaggle con 240,000 canciones que ya inclu칤a 11 caracter칤sticas de audio extra칤das por Spotify (como `valence`, `energy`, `danceability`)."
    - "Cambiamos nuestro modelo a una Red Neuronal Densa (DNN), que es ideal para este tipo de datos tabulares."
        
- **Fase 3: El Gran Hallazgo (El Problema de la clase "Calma")**
    
    - "Este nuevo modelo nos permiti칩 hacer un diagn칩stico real. El modelo funcionaba bien, pero segu칤a fallando estrepitosamente en una clase: 'Calma'."
    - (Aqu칤 abren `metrics.html` y se침alan la gr치fica de **Balanceo de Clases**).
    - "Como pueden ver, la clase 'Calma' estaba severamente desbalanceada. Intentamos solucionarlo con t칠cnicas como `SMOTE` y `class_weight`, pero los resultados no mejoraron."
    - "**Nuestra Conclusi칩n Clave:** El problema no era el modelo, eran los datos. Las caracter칤sticas de audio de una canci칩n de 'Calma' son s칩nicamente ambiguas, se parecen demasiado a 'Tristeza' y a 'Felicidad'. Era imposible para el modelo separarlas."
        
- **Fase 4: La Soluci칩n (El Modelo de 3 Clases)**
    
    - "Basados en este hallazgo, tomamos la decisi칩n de ingenier칤a m치s importante: **eliminamos la clase 'Calma' del entrenamiento**."
    - "Esto nos permiti칩 entrenar un modelo experto y altamente preciso en las 3 clases que s칤 son distinguibles: **Ira, Tristeza y Felicidad**. Como ven en la gr치fica de balanceo, esto nos dio un dataset casi perfecto."
    - "Cumplimos el objetivo, porque nuestro sistema _no necesita_ predecir 'Calma', solo necesita saber c칩mo _recomendar_ 'Calma'."
        
- **Fase 5: Retos de Integraci칩n (La API de Spotify)**
    
    - "Finalmente, conectamos nuestro modelo a la API de Spotify. Aqu칤 superamos dos retos finales:"
        
    
    1. **Error 403 (Bloqueo):** La API nos bloqueaba. Lo resolvimos creando una nueva cuenta de desarrollador desde cero.
    2. **Error 404 (No encontrado):** El plan original de usar `sp.recommendations` fallaba porque nuestras peticiones eran demasiado estrictas. Pivotamos a una soluci칩n m치s robusta: usamos `sp.search(type='playlist')`. En lugar de _crear_ una playlist, _buscamos_ playlists de mitigaci칩n (ej. "m칰sica para calmar") hechas por humanos y le presentamos esas canciones al usuario."
        

### 4. Demostraci칩n y Resultados (La "Prueba") 游

**(Aqu칤 ejecutan la demo `index.html` y la vista de `metrics.html`).**

**Ustedes:** "El resultado es el prototipo que ven aqu칤.

- **(Paso 1: Demo)** "El usuario busca una canci칩n de nuestra base de datos. Por ejemplo, 'Chop Suey', que es una canci칩n de 'Ira'."
- **(Paso 2: Modelo)** "Nuestro modelo la analiza y, como ven, la clasifica como 'Ira' con un **(X)% de confianza**."
- **(Paso 3: Mitigaci칩n)** "Basado en esa predicci칩n, el backend busca aleatoriamente playlists con t칠rminos como 'm칰sica para calmar' o 'chill vibes'."
- **(Paso 4: Resultado)** "Y le presenta al usuario una playlist de mitigaci칩n funcional, con links directos a Spotify."
    

**(Ahora, cambien a la pesta침a `metrics.html`).**

**Ustedes:** "Y para los jurados, aqu칤 est치 la justificaci칩n de por qu칠 este modelo es confiable:

1. **(Se침alen la Arquitectura)**: "Esta es la arquitectura de nuestra Red Neuronal Densa de 4 capas."
2. **(Se침alen el Reporte de Clasificaci칩n)**: "Aqu칤 vemos las m칠tricas clave. El modelo tiene un **F1-Score** alto y balanceado para las 3 clases, lo que demuestra que es preciso y no est치 sesgado."
3. **(Se침alen la Matriz de Confusi칩n)**: "Y la matriz de confusi칩n confirma visualmente que el modelo es excelente para distinguir entre las 3 clases."
    

### 5. Conclusi칩n (El Cierre)

**Ustedes:** "En conclusi칩n, hemos cumplido todos los objetivos del proyecto.

1. **Recolectamos y preparamos** un dataset masivo.
2. **Implementamos y optimizamos** un modelo de Deep Learning, justificando cada decisi칩n.
3. **Dise침amos un algoritmo** de recomendaci칩n robusto.
4. Y **evaluamos** su calidad con m칠tricas est치ndar.
    

M치s que una simple aplicaci칩n, construimos un prototipo que demuestra un **proceso de investigaci칩n completo**, desde el fracaso inicial hasta el diagn칩stico de un problema de datos y la implementaci칩n de una soluci칩n de ingenier칤a efectiva.

Como trabajo futuro, este sistema podr칤a expandirse para analizar playlists completas o permitir al usuario elegir el tipo de mitigaci칩n que prefiere."

"Muchas gracias."

# Preguntas de Fogueo

### Respuestas Sugeridas (Rol: Estudiante)

#### Sobre la Metodolog칤a y el Pivoteo

**1. Usted propuso un objetivo (Obj. 2) que menciona "procesamiento de audio" y "t칠cnicas de deep learning". Sin embargo, su modelo final (un DNN) no procesa audio; procesa un CSV. 쯅o considera esto un incumplimiento de su propio objetivo? 쯇or qu칠 un DNN sobre un CSV es un proyecto de noveno semestre?**

- **Respuesta:**
    
    - "Gracias por la pregunta. El objetivo 2 se cumple, pero de una forma m치s eficiente. El proyecto utiliza t칠cnicas de Deep Learning (una Red Neuronal Densa o DNN) aplicadas a _datos procesados de audio_.
        
    - Mi investigaci칩n inicial (la Fase 1 con la CNN) consisti칩 en procesar el audio yo mismo usando Librosa. Sin embargo, los resultados demostraron que esta extracci칩n de caracter칤sticas era sub칩ptima y generaba un modelo de baja calidad.
        
    - Tom칠 una decisi칩n de ingenier칤a: en lugar de reinventar la rueda, decid칤 apalancarme en el procesamiento de audio de nivel industrial que ya realiza Spotify. Las 11 caracter칤sticas del dataset de Kaggle _son_ el resultado de un procesamiento de audio avanzado.
        
    - Mi modelo de Deep Learning (el DNN) aprende de estas caracter칤sticas de alto nivel. Esto no es un incumplimiento, es una optimizaci칩n. Un proyecto de noveno semestre tambi칠n consiste en saber _integrar_ y _construir sobre_ herramientas existentes, en lugar de construir todo desde cero de forma ineficiente."
        

**2. Usted invirti칩 tiempo en un modelo CNN con Librosa, que fall칩. Luego cambi칩 a un DNN con un dataset de Kaggle. 쮺칩mo justifica este "pivote"? 쯅o es esto simplemente un manejo deficiente de la incertidumbre del proyecto? 쯇or qu칠 deber칤amos ver esto como una optimizaci칩n y no como un error de planificaci칩n?**

- **Respuesta:**
    
    - "Al contrario. Lo veo como la validaci칩n de un proceso de investigaci칩n y desarrollo 치gil. La planificaci칩n inicial conten칤a una **hip칩tesis**: _'Es posible crear un modelo CNN preciso a partir de espectrogramas Mel para esta tarea'_.
        
    - Mi trabajo en la Fase 1 fue **testear esa hip칩tesis**. Los resultados (el `recall` de 9% para 'Calma') **refutaron la hip칩tesis**, demostrando que, con las herramientas a mi alcance, las caracter칤sticas no eran lo suficientemente separables.
        
    - El "pivote" no fue un error, fue la **conclusi칩n l칩gica** de esa primera fase experimental. Demuestra que el proyecto no se aferr칩 a un plan fallido, sino que se adapt칩 a la evidencia, que es un pilar de la ingenier칤a. La optimizaci칩n fue abandonar un callej칩n sin salida para tomar una ruta m치s prometedora que, como vemos en los resultados finales, fue exitosa."
        

**3. Su primer modelo (CNN de 4 clases) fall칩. El segundo (DNN de 4 clases) tambi칠n fall칩. 쯇or qu칠 insisti칩 en usar Deep Learning? 쯇or qu칠 no prob칩 un modelo de Machine Learning tradicional como Random Forest o SVM? 쮺칩mo sabe que su DNN de 65% de precisi칩n es mejor que un SVM que quiz치s le daba 75% con menos esfuerzo?**

- **Respuesta:**
    
    - "Esa es una excelente pregunta metodol칩gica. Mi insistencia en Deep Learning se debi칩 a dos razones:
        
        1. **Requisito del Proyecto:** El Objetivo Espec칤fico 2 nos ped칤a expl칤citamente "utilizar t칠cnicas de deep learning". Esto restringi칩 mi conjunto de herramientas.
            
        2. **Escalabilidad:** Las Redes Neuronales Densas (DNN) son excelentes para encontrar patrones no lineales complejos en grandes datasets como el que us칠 (m치s de 200,000 muestras).
            
    - Ahora, reconozco que un modelo cl치sico como Random Forest o XGBoost podr칤a, en efecto, tener un rendimiento igual o superior en este tipo de datos tabulares. Una **comparativa de benchmarks** entre mi DNN final y un modelo como Random Forest ser칤a una parte fundamental del _trabajo futuro_ para optimizar a칰n m치s el sistema. Para el alcance de este semestre, el desaf칤o era implementar un pipeline _completo_ usando Deep Learning, y eso fue lo que se logr칩."
        

---

#### Sobre el Dataset y las Caracter칤sticas

**4. Su modelo final se entrena con datos de Spotify de 2018 y 2019. La m칰sica ha cambiado. 쯅o est치 su modelo entrenado con datos obsoletos? 쯈u칠 validez tiene este modelo para predecir la emoci칩n de una canci칩n de 2025?**

- **Respuesta:**
    
    - "Es una preocupaci칩n v치lida sobre el _model drift_. Sin embargo, el modelo no est치 aprendiendo 'canciones de 2019'. Est치 aprendiendo la **relaci칩n fundamental entre las caracter칤sticas de audio y la emoci칩n humana.**
        
    - Es decir, aprende que las canciones con baja energ칤a, tonalidad menor y poca 'danceability' tienden a ser tristes. Esas reglas psicoac칰sticas son, en gran medida, atemporales. Una balada triste de 2025 compartir치 muchas de esas mismas caracter칤sticas con una de 2018.
        
    - Dicho esto, un sistema en producci칩n real necesitar칤a un pipeline de **reentrenamiento continuo** con datos nuevos para ajustarse a las tendencias de producci칩n musical. Pero para un prototipo, este dataset de 130,000 canciones es una base robusta para aprender esos patrones fundamentales."
        

**5. Su modelo de cuadrantes (Valencia-Energ칤a) es una simplificaci칩n radical de la emoci칩n humana. 쯈u칠 pasa con las canciones "agridulces" (alta valencia, baja energ칤a pero tristes)? 쯅o es esta premisa fundamentalmente err칩nea y demasiado arbitraria?**

- **Respuesta:**
    
    - "Tiene toda la raz칩n. El modelo de 2 dimensiones de Russell (Valencia-Arousal) es una **abstracci칩n**, y como toda abstracci칩n, tiene limitaciones. La emoci칩n humana es mucho m치s compleja.
        
    - Para este proyecto, adoptamos este modelo porque es el **est치ndar de la industria** (Spotify mismo lo usa con sus m칠tricas `valence` y `energy`) y nos da un marco de trabajo objetivo y medible.
        
    - Nuestro sistema no puede, por dise침o, capturar la ambig칲edad de una canci칩n "agridulce". Ese ser칤a un desaf칤o mucho m치s complejo, que probablemente requerir칤a el an치lisis de la letra (NLP) y caracter칤sticas m치s avanzadas. Para el alcance de este prototipo, decidimos aceptar esta limitaci칩n y enfocarnos en las cuatro emociones cardinales que el modelo s칤 puede representar."
        

**6. Su soluci칩n final fue eliminar la clase "Calma". 쯅o es esto simplemente "barrer el problema debajo de la alfombra"? 쮺칩mo puede un sistema de "detecci칩n de emociones" ser robusto si intencionalmente ignora una de las cuatro emociones fundamentales?**

- **Respuesta:**
    
    - "Esta fue una de las decisiones de dise침o m치s importantes. No ignoramos la emoci칩n 'Calma'; **cambiamos la forma en que el sistema interact칰a con ella.**
        
    - Mis experimentos demostraron que, con las 11 caracter칤sticas de Spotify, el modelo era **incapaz** de distinguir 'Calma' de las otras clases (`recall` del 9%). Insistir en predecir una clase ambigua estaba _da침ando_ la precisi칩n de las clases que s칤 eran claras.
        
    - El objetivo del proyecto es la _mitigaci칩n_. Mi sistema _a칰n_ recomienda 'Calma'. Cuando detecta 'Ira', el algoritmo de recomendaci칩n sabe perfectamente c칩mo buscar canciones de 'Calma': lo hace **filtrando el cat치logo de Spotify** (`valence >= 0.5` y `energy < 0.5`).
        
    - Separamos las responsabilidades: el **modelo de IA** se encarga de la detecci칩n _dif칤cil_ (Ira, Tristeza, Felicidad), y el **algoritmo de recomendaci칩n** se encarga de la identificaci칩n _f치cil_ (Calma). Esto crea un sistema general mucho m치s robusto y preciso."
        

---

#### Sobre el Modelo y los Resultados

**7. Su reporte final muestra un F1-score de 0.80 para "Tristeza", pero 0.59 para "Felicidad" e "Ira". Un 59% es apenas mejor que adivinar. 쮺칩mo puede estar listo para un front-end un modelo que, en 2 de sus 3 funciones, se equivoca casi la mitad de las veces?**

- **Respuesta:**
    
    - "Aqu칤 es clave el contexto. El _baseline_ o l칤nea base no es 0%, es 33% (adivinar al azar entre 3 clases). Un F1-score de 0.59 est치 significativamente por encima de eso y demuestra un aprendizaje real.
        
    - Lo m치s importante para un sistema de _mitigaci칩n_ es la clase **'Tristeza'**, y ah칤 el modelo es **muy robusto, con un 80% de F1-score**. Esto significa que el caso de uso principal del prototipo funciona muy bien.
        
    - Los scores de 0.59 para 'Ira' y 'Felicidad' indican que el modelo es 'decente' y funcional para un prototipo. No es un modelo de precisi칩n quir칰rgica, pero es un **Producto M칤nimo Viable** exitoso. El flujo completo funciona, y los resultados son lo suficientemente buenos como para validar el concepto y pasar a la integraci칩n con el front-end."
        

**8. Mu칠streme la arquitectura de su DNN. 쯇or qu칠 `Dense(128)`? 쯇or qu칠 no 64 o 256? 쯇or qu칠 un `Dropout` de 0.5 y no de 0.2? 쯆 simplemente copi칩 esta arquitectura de un tutorial? 쮺u치l fue su proceso metodol칩gico para la sintonizaci칩n de hiperpar치metros?**

- **Respuesta:**
    
    - "La arquitectura (`128 -> 64 -> 32`) sigue una estructura de 'embudo' (funneling), que es una pr치ctica est치ndar para datos tabulares, donde se busca condensar la informaci칩n progresivamente.
        
    - La capa inicial de 128 neuronas se eligi칩 para ser significativamente m치s grande que el vector de entrada (de 11 caracter칤sticas), d치ndole al modelo espacio suficiente para aprender combinaciones complejas.
        
    - Los valores de `Dropout` (0.5, 0.3) se eligieron deliberadamente altos como una medida de **regularizaci칩n fuerte** para prevenir el _overfitting_, que fue el principal problema que identifiqu칠 en la Fase 1 del proyecto.
        
    - Admito que esta arquitectura no es el resultado de una sintonizaci칩n de hiperpar치metros exhaustiva (como un GridSearch o KerasTuner), lo cual ser칤a un paso obvio de optimizaci칩n futura. Esta arquitectura se seleccion칩 como un **punto de partida robusto y est치ndar** para validar el modelo de 3 clases."
        

**9. Su sistema detecta "Tristeza" y recomienda "Felicidad". Detecta "Ira" y recomienda "Calma". Esta l칩gica de mitigaci칩n es muy simplista. 쯈u칠 pasa si un usuario est치 enojado y _quiere_ escuchar m칰sica de "Ira" para catarsis? 쯅o est치 usted imponiendo una experiencia de usuario (UX) en lugar de asistir al usuario?**

- **Respuesta:**
    
    - "Esa es una observaci칩n de UX excelente. El alcance de este prototipo era implementar un sistema de **mitigaci칩n** (es decir, contrarrestar la emoci칩n). El `mitigation_map` que dise침칠 cumple ese objetivo espec칤fico.
        
    - Usted tiene raz칩n: un sistema completo no solo deber칤a mitigar, sino tambi칠n permitir la _exploraci칩n_ o _catarsis_. En una versi칩n futura, el front-end deber칤a preguntar al usuario: 'Detectamos Ira. 쯈uieres calmarte o quieres explorar esta emoci칩n?'
        
    - Mi prototipo actual implementa el _backend_ t칠cnico para una de esas dos rutas. La l칩gica de recomendaci칩n es un m칩dulo intercambiable; el sistema de IA que lo alimenta es robusto."
        

---

#### Sobre la Implementaci칩n y el Sistema

**10. Usted mencion칩 la posibilidad de subir un MP3. Propone usar una API como ACRCloud para identificar la canci칩n y luego buscarla en Spotify. 쮿a medido la latencia de esa tuber칤a (pipeline)? 쮺u치nto tiempo real pasa desde que el usuario sube el MP3 hasta que se genera la playlist? 쮼s aceptable para un usuario final?**

- **Respuesta:**
    
    - "No he implementado a칰n esa funcionalidad, pero he analizado su viabilidad. La latencia estimada ser칤a una suma de varias llamadas:
        
        1. La subida del archivo (depende del usuario).
            
        2. La llamada a la API de fingerprinting (ACRCloud), que suele tardar entre 2 y 5 segundos.
            
        3. Dos llamadas a la API de Spotify (una para `audio_features` y otra para crear la playlist), que son muy r치pidas, probablemente 1-2 segundos en total.
            
        4. La predicci칩n del modelo local, que es casi instant치nea (milisegundos).
            
    - La latencia total activa estar칤a en el rango de **5 a 8 segundos**. Para una operaci칩n "pesada" como procesar un archivo nuevo, esta latencia se considera aceptable para una experiencia de usuario, similar a lo que tarda Shazam."
        

**11. 쯈u칠 pasa si el usuario sube una canci칩n que no est치 en Spotify o en la base de datos de ACRCloud? 쯉implemente falla? 쯈u칠 manejo de excepciones implement칩 para ese caso de uso?**

- **Respuesta:**
    
    - "Ese es un caso de uso cr칤tico. El sistema no debe fallar con un error 500. La implementaci칩n correcta, que est치 contemplada, usar칤a un manejo de excepciones (`try...except`).
        
    - El flujo de la API de reconocimiento estar칤a envuelto en un bloque `try`. Si la API de ACRCloud devuelve un 'No Encontrado', el `except` capturar칤a ese error y le devolver칤a un mensaje JSON claro al front-end, algo como: `{'status': 'error', 'message': 'Lo sentimos, no pudimos identificar esta canci칩n. Aseg칰rate de que sea m칰sica comercial y no una grabaci칩n local.'}`. El front-end ser칤a responsable de mostrar ese mensaje amigable al usuario."
        

**12. (Pregunta de Fogueo) 쮺u치l es el costo computacional y econ칩mico de su soluci칩n? 쮺u치nto costar칤a mantener este sistema si tuviera 10,000 usuarios activos al mes?**

- **Respuesta:**
    
    - "El costo se divide en dos:
        
        1. **Mi Modelo (Costo bajo):** El modelo DNN es un archivo de pocos megabytes. La predicci칩n (inferencia) es computacionalmente muy barata. Podr칤a desplegarse en un servicio _serverless_ como AWS Lambda o Google Cloud Functions, donde el costo por 10,000 predicciones ser칤a de **centavos de d칩lar**.
            
        2. **Las APIs (Costo real):** Aqu칤 es donde est치 el costo. La API de Spotify tiene un nivel gratuito generoso, por lo que probablemente no ser칤a un problema. Sin embargo, la API de reconocimiento de MP3 (ACRCloud) s칤 tiene costos asociados. Su plan gratuito no soportar칤a 10,000 usuarios, por lo que el proyecto tendr칤a que escalar a un plan de pago, cuyo costo depender칤a del n칰mero de subidas de MP3.
            
    - En resumen: el costo de _mi_ desarrollo de IA es casi nulo. El costo de la _funcionalidad_ de subir MP3 depender칤a de un proveedor externo."
        

---

#### Pregunta de Cierre (Defensa)

**13. Ingeniero, sea honesto. Despu칠s de toda esta experimentaci칩n, 쯡o habr칤a sido m치s r치pido, barato y preciso saltarse el Deep Learning por completo y simplemente usar la API de Spotify, pedir las `audio_features` y aplicar su l칩gica de cuadrantes directamente? 쯈u칠 valor real aport칩 su modelo de Deep Learning al sistema final?**

- **Respuesta:**
    
    - "Esa es la pregunta central del proyecto, y la respuesta es **no, no habr칤a sido mejor**, y el modelo de Deep Learning es el **componente que m치s valor aporta.**
        
    - Si yo solo usara los dos ejes (`valence` y `energy`) para aplicar la l칩gica de cuadrantes, mi sistema ser칤a una copia exacta de la clasificaci칩n que ya hicimos para etiquetar el dataset, y estar칤a sujeto a todos sus errores.
        
    - El valor de mi modelo DNN de 3 clases es que aprendi칩 a predecir la emoci칩n **usando 11 caracter칤sticas, no solo 2**. Mi modelo aprendi칩 patrones m치s sutiles.
        
    - Por ejemplo, mi modelo obtuvo un **80% de F1-score en 'Tristeza'**. Esto significa que aprendi칩 que 'Tristeza' no es solo 'baja valencia y baja energ칤a', sino que tambi칠n es una combinaci칩n espec칤fica de alta `acousticness`, bajo `tempo`, y baja `danceability`.
        
    - El modelo de Deep Learning **es un clasificador mucho m치s inteligente y preciso** que una simple divisi칩n de cuadrantes. Va m치s all치 de los dos ejes obvios y encuentra las relaciones ocultas en las otras 9 caracter칤sticas, d치ndome un detector de 'Tristeza' e 'Ira' mucho m치s robusto. Ese es su valor real."

