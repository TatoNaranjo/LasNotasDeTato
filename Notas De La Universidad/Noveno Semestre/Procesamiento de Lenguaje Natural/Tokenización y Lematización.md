---
date: 2025-08-28
---
La tokenización es el paso inicial del procesamiento del lenguaje natural. Aquí el texto se divide en palabras o frases individuales llamadas tokens.

Librerías: NLTK, spaCy, Gensim
Funciones de envoltura: Word_Tokenize

En NLTK, PUNKT es un modelo entrenable no supervisado, lo que significa que se puede entrenar con datos no etiquetados.

